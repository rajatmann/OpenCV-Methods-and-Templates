{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20e012d-d91f-4c82-a926-811a4e166cd6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35d0a34a-6e8c-4001-a107-6648b82391fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35f916c-79c3-4feb-9c84-f373d5be31b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the image\n",
    "img = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\logo.png', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e86aae4-4c9d-4e7a-a2fa-034dd0a54d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a window and displaying the image\n",
    "cv2.imshow('Image',img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc6532d-63e4-4cb5-8bcc-29695cb4968f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (400,400))#resizing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a81c89a-9b56-4a0e-b61b-7335829a3285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (0,0), fx =0.1, fy =0.1)#resizing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75541419-1a57-44b6-974f-c1240ba7e937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.rotate(img, cv2.ROTATE_180)#Rotating an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5199218e-0759-4c4e-b345-0acf09cb2c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\logo1.jpg', img)#will be saved as a new file in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad64401-d91b-454d-b969-26d478032beb",
   "metadata": {},
   "source": [
    "# Image Fundamentals and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11b6465b-6aa8-4c2b-82e2-813ade18bbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the image\n",
    "img = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\logo1.jpg', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74544a73-f663-469a-8e91-4b806db1897f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "245cd738-b9e6-4775-abda-78f2d5f682f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifying few rows in our image\n",
    "import random\n",
    "for i in range(100):\n",
    "    for j in range(img.shape[1]):\n",
    "        img[i][j] = [random.randint(0,255), random.randint(0,255), random.randint(0,255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "135d5cfd-364e-460c-bb9c-d4600252cae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing a slice of our image with another slice\n",
    "tag = img[200:500, 200:500]\n",
    "img[100:400,400:700] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a652ef3-5892-4d7d-bfb1-e4ae2f12d083",
   "metadata": {},
   "source": [
    "# Cameras and Video Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "562b8d24-1d1f-4eca-b7d5-be03359b252f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18b23dd-87ee-463a-8fb1-60edc8d91ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # 0 for the number of webcams\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68cb6ed3-1eb5-4efb-9446-b9ece3e5d290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# showing 4 of me\n",
    "cap = cv2.VideoCapture(0) # 0 for the number of webcams\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    width = int(cap.get(3)) #3 is width\n",
    "    height = int(cap.get(4)) # 4 is height\n",
    "    \n",
    "    image = np.zeros(frame.shape, np.uint8)   \n",
    "    smaller_frame = cv2.resize(frame, (0,0), fx =0.5, fy =0.5)\n",
    "    \n",
    "    image[:height//2,:width//2] =  cv2.rotate(smaller_frame, cv2.ROTATE_180)\n",
    "    image[height//2:,:width//2] = smaller_frame\n",
    "    image[:height//2,width//2:] =  smaller_frame\n",
    "    image[height//2:,width//2:] =  cv2.rotate(smaller_frame, cv2.ROTATE_180)\n",
    "    \n",
    "    cv2.imshow('4frame', image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac6830-8ada-4dd6-b1bb-c034f8353ed6",
   "metadata": {},
   "source": [
    "# Drawing Lines, Images, Circles and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6eaa4df-d607-4890-8b6d-8c0ebf23ca60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drawing on our cam\n",
    "cap = cv2.VideoCapture(0) # 0 for the number of webcams\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    width = int(cap.get(3)) #3 is width\n",
    "    height = int(cap.get(4)) # 4 is height\n",
    "    \n",
    "    img = cv2.line(frame, (0,0),(width,height), (255,0,0), 10)\n",
    "    img = cv2.line(frame, (0,height),(width,0), (255,0,0), 10)\n",
    "    img = cv2.rectangle(img, (100,100), (200,200), (128,5,12),5)\n",
    "    img = cv2.circle(img, (150,150), 60, (0,0,255), 5)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    img = cv2.putText(img, 'Hi, I am Rajat', (200, height-10), font,1, (0,0,0), 5, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', img)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3513ff-8da9-44d3-939e-3557f37d6fe2",
   "metadata": {},
   "source": [
    "# Colors and Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db837aa4-b3e3-4862-8ea0-d76988bd8402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Detecting colors in an image by converting it to HSV\n",
    "cap = cv2.VideoCapture(0) # 0 for the number of webcams\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    width = int(cap.get(3)) #3 is width\n",
    "    height = int(cap.get(4)) # 4 is height\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([90,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    result = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('result', result)\n",
    "    cv2.imshow('mask', mask)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7aff7-a1db-4a06-b7f6-875710fbd4d4",
   "metadata": {},
   "source": [
    "# Corner Detection using Shi-Tomasi detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bf635887-ba29-4e80-bd78-98242dc7227e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the image\n",
    "img = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\corner.jpg', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c12652e9-9c66-4a84-98e8-99e2b31b338e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a window and displaying the image\n",
    "cv2.imshow('Image',img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fe64e3e7-9dad-4318-9507-1fc1ac301a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (0,0),fx = 0.4, fy = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb22e8e7-32cb-428d-b2ab-e219f50b6cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#converting to grayscale becasue many such algos run on grayscale images\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6222232f-e229-4fd2-8483-855862ccdf75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[457., 481.]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01,10) #100 is the number of best corners\n",
    "corners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d17be7af-b202-4307-b85b-b003ae02fb2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corners = np.int0(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f16fa712-ff93-4b62-b7ba-5d7e8d593a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[457, 481]], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "221e0dc3-5295-4486-b754-165a68e7ef42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "    cv2.circle(img, (x,y), 10, (255,0,0),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a681a7eb-9ff1-490f-87f3-02e5770b05d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(corners)):\n",
    "    for j in range(i+1, len(corners)):\n",
    "        corner1 = tuple(corners[i][0])\n",
    "        corner2 = tuple(corners[j][0])\n",
    "        color = tuple(map(lambda x: int(x), np.random.randint(0,255,size = 3)))\n",
    "        cv2.line(img, corner1, corner2, color, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae6fee4-4540-4659-9687-c760da985ce8",
   "metadata": {},
   "source": [
    "# Template Matching/Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1957c54d-02db-4f5c-9de0-9216c5afb619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the image\n",
    "img = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\football.jpg', 0)\n",
    "temp1 = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\football_template.jpg', 0)\n",
    "temp2 = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\white_sock.jpg', 0)\n",
    "temp3 = cv2.imread(r'C:\\Users\\rajat\\OneDrive\\Desktop\\OpenCVFiles\\assets\\black_sock.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c419d1ed-ca5a-4f1e-b334-628c351b3d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h, w = temp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "94f5ada1-5584-4265-9bc2-6ad0d2a012a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR,\n",
    "            cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "08a75f01-98ae-4d97-9889-49dbf16483c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    img2 = img.copy()\n",
    "    result = cv2.matchTemplate(img2, temp1, method) # This basically performs a convolution on our image using template as the filter\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        location = min_loc\n",
    "    else:\n",
    "        location = max_loc\n",
    "    \n",
    "    bottom_right = (location[0]+w, location[1] +h)\n",
    "    cv2.rectangle(img2, location,  bottom_right, 255, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "297e4421-3f0b-49c2-bc36-d22ef9d7dc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a window and displaying the image\n",
    "cv2.imshow('Image',img2) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf7c1e-0c0c-4baa-b665-02f23f52ce19",
   "metadata": {},
   "source": [
    "# Face and Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "17f8509d-8426-4745-9a97-534330799028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#face and eye detection usuing cascade method\n",
    "cap = cv2.VideoCapture(0) # 0 for the number of webcams\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0),5)\n",
    "        roi_gray =gray[y:y+w, x:x+w]\n",
    "        roi_color = frame[y:y+w, x:x+w]# we make this because the orignal image has different number of frames compared to gray image\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.3,5)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey),(ex+ew,ey+eh), (0,255,0), 5)\n",
    "            \n",
    "    cv2.imshow('result', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf4cc6-ad35-46c4-b2f4-3765ab5efc02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
